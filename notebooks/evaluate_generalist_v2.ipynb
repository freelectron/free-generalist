{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Should be first to load all the env vars for browser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"CHROME_USER_DATA_DIR\", None)\n",
    "\n",
    "# Needed to use the static/ default folder with the cache\n",
    "from browser import BRAVE_SEARCH_SESSION\n",
    "\n",
    "BRAVE_SEARCH_SESSION.browser.chrome_user_data_dir"
   ],
   "id": "9cbf16c8387e05f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62b3a119",
   "metadata": {},
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from generalist.agents.core import AgentPlan\n",
    "from generalist.tools.data_model import ContentResource, ShortAnswer, Task\n",
    "\n",
    "class ExecutionState(TypedDict):\n",
    "    # what user is asking to do for them \n",
    "    ask: str\n",
    "    # Identifies what the original question/task given, which objective it got transferred to, what the plan to get an answer is\n",
    "    task: Task\n",
    "    # order index of the step of the task's plan that is being executed \n",
    "    step: int\n",
    "    # Clues, findings and answers to the previous subtasks\n",
    "    # Used to execute a capability plan step given already found information\n",
    "    context: str  \n",
    "    # capability plan for this task (overwritten when a new subtask from the main plain is picked up)\n",
    "    capability_plan: AgentPlan\n",
    "    # capability plan step order \n",
    "    capability_plan_step: int\n",
    "    # answers to subtask, the last one should be the final answer to the task \n",
    "    answers: list[ShortAnswer]\n",
    "    # all text resources that might be needed to execute the task\n",
    "    resources: list[ContentResource]\n",
    "    # tools that already got called\n",
    "    # TODO: see if this is needed \n",
    "    tools_called: str\n",
    "\n",
    "MAX_STEPS = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "695079d0",
   "metadata": {},
   "source": [
    "import json\n",
    "from generalist.agents.core import AgentDeepWebSearch, AgentUnstructuredDataProcessor, \\\n",
    "    AgentCodeWriterExecutor, AgentAudioProcessor, AgentOutput\n",
    "from generalist.tools.planning import determine_capabilities, create_plan\n",
    "from generalist.tools.summarisers import construct_short_answer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def init_state(ask: str, resources: list[ContentResource] | None = None) -> ExecutionState:\n",
    "    return ExecutionState(\n",
    "        ask=ask,\n",
    "        task=None,\n",
    "        step=None,\n",
    "        context=\"\",\n",
    "        answers=list(),\n",
    "        resources=resources if resources else [],\n",
    "    )\n",
    "\n",
    "def set_task(state: ExecutionState) -> ExecutionState:\n",
    "    question_task = state[\"ask\"]\n",
    "    task_plan_response = create_plan(question_task)\n",
    "\n",
    "    result = json.loads(task_plan_response)\n",
    "    task = Task(\n",
    "      question=question_task,\n",
    "      objective=result[\"objective\"],\n",
    "      plan=result[\"plan\"],\n",
    "    )\n",
    "    identified_resource = result.get(\"resource\", None)\n",
    "    if identified_resource:\n",
    "        task_resource = ContentResource(\n",
    "            provided_by=\"user\",\n",
    "            content=identified_resource.get(\"content\", None),\n",
    "            link=identified_resource.get(\"link\", None),\n",
    "            metadata={},\n",
    "        )\n",
    "        state[\"resources\"].append(task_resource)\n",
    "    state[\"task\"] = task\n",
    "\n",
    "    state[\"step\"] = 0\n",
    "    return state\n",
    "\n",
    "def evaluate_task_completion(state: ExecutionState) -> str:\n",
    "    short_answer = construct_short_answer(\n",
    "        state[\"task\"].objective,\n",
    "        state[\"context\"]\n",
    "    )\n",
    "\n",
    "    # Early stopping if answer exists\n",
    "    if short_answer.answered:\n",
    "        return \"end\"\n",
    "\n",
    "    # Early stopping if maximum number of steps reached\n",
    "    if state['step'] >= MAX_STEPS:\n",
    "        return \"end\"\n",
    "\n",
    "    return \"continue\"\n",
    "\n",
    "def plan_next_step(state: ExecutionState) -> ExecutionState:\n",
    "    # Automatically determine which step to execute based on context\n",
    "    capability_plan_json = determine_capabilities(\n",
    "        task=state[\"task\"],\n",
    "        context=state[\"context\"]\n",
    "    )\n",
    "\n",
    "    state[\"capability_plan\"] = AgentPlan.from_json(capability_plan_json)\n",
    "    return state\n",
    "\n",
    "def execute(state: ExecutionState) -> ExecutionState:\n",
    "    activity, capability = state[\"capability_plan\"].subplan[0]\n",
    "    output = AgentOutput(activity)\n",
    "    capability_agent = capability(activity)\n",
    "    if capability is AgentDeepWebSearch:\n",
    "        output = capability_agent.run()\n",
    "    elif capability is AgentUnstructuredDataProcessor:\n",
    "        output = capability_agent.run(state[\"resources\"])\n",
    "    elif capability is AgentCodeWriterExecutor:\n",
    "        output = capability_agent.run(state[\"resources\"])\n",
    "    elif capability is AgentAudioProcessor:\n",
    "        output = capability_agent.run(state[\"resources\"])\n",
    "    else:\n",
    "        print(\"DEBUG | run_capability | Call to unidentified agent: \", capability)\n",
    "\n",
    "    if output.answers:\n",
    "        state[\"answers\"].extend(output.answers)\n",
    "    if output.resources:\n",
    "        state[\"resources\"].extend(output.resources)\n",
    "\n",
    "    # Update context with step results\n",
    "    state[\"context\"] += f\"\\nStep {capability_agent.name}: {state['answers']}\"\n",
    "    state[\"step\"] += 1\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=ExecutionState)\n",
    "\n",
    "workflow.add_node(\"set_task\", set_task)\n",
    "workflow.add_node(\"plan_next_step\", plan_next_step)\n",
    "workflow.add_node(\"execute\", execute)\n",
    "\n",
    "workflow.add_edge(START, \"set_task\")\n",
    "workflow.add_edge(\"set_task\", \"plan_next_step\")\n",
    "workflow.add_edge(\"plan_next_step\", \"execute\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"execute\",\n",
    "    evaluate_task_completion,\n",
    "    {\n",
    "        \"continue\": \"plan_next_step\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "generalist_graph = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(generalist_graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import mlflow\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "gaia_path = os.environ.get(\"HUGGING_FACE_GAIA_FOLDER_PATH\")\n",
    "data_dir = snapshot_download(local_dir=gaia_path,  local_files_only=True, repo_id=\"gaia-benchmark/GAIA\", repo_type=\"dataset\")\n",
    "\n",
    "dataset = load_dataset(data_dir, \"2023_level1\", split=\"validation\")\n",
    "gaia_keys = ['task_id', 'Question', 'Level', 'Final answer', 'file_name', 'file_path', 'Annotator Metadata']\n",
    "\n",
    "sosa_many_studio_albums_task_id = \"8e867cd7-cff9-4e6c-867a-ff5ddc2550be\" # web search\n",
    "running_to_the_moon_task_id = \"e1fc63a2-da7a-432f-be78-7c4a95598703\"  # web search + calculating\n",
    "dr_who_season_9_eps_11_location_task_id = \"4b6bb5f7-f634-410e-815d-e673ab7f8632\" # web search and pdf reading\n",
    "calc_sales_xlsx_task_id = \"7bd855d8-463d-4ed5-93ca-5fe35145f733\"\n",
    "just_running_python_task_id = \"f918266a-b3e0-4914-865d-4faa564f1aef\"\n",
    "looking_up_paper_authors_task_id = \"46719c30-f4c3-4cad-be07-d5cb21eee6bb\" # web search + possibly pdf reading from online\n",
    "dinosaur_article_task_id = \"4fc2f1ae-8625-45b5-ab34-ad4433bc21f8\" # web search\n",
    "merriam_webster_word_task_id = \"5188369a-3bbe-43d8-8b94-11558f909a08\" # web search\n",
    "reading_txt_and_solving_puzzle_task_id = \"389793a7-ca17-4e82-81cb-2b3a2391b4b9\"\n",
    "teal_video_task_id = \"9d191bce-651d-4746-be2d-7ef8ecadb9c2\"\n",
    "very_specific_web_search_download_task_id = \"cabe07ed-9eca-40ea-8ead-410ef5e83f91\"\n",
    "listening_to_recipe_task_id = \"99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3\" # audio processing\n",
    "scikit_learn_change_log_task_id = \"d0633230-7067-47a9-9dbf-ee11e0a2cdd6\" # web search + code processing\n",
    "polish_raymond_task_id = \"305ac316-eef6-4446-960a-92d80d542f82\"\n",
    "baseball_table_processing_task_id = \"3f57289b-8c60-48be-bd80-01f8099ca449\" # web search + online table processing\n",
    "audio_processing_homework_task_id = \"1f975693-876d-457b-a649-393859e79bf3\"\n",
    "mulitstep_browser_search_on_a_website_task_id = \"a0068077-79f4-461a-adfe-75c1a4148545\"\n",
    "kuznetsov_paper_st_petersburg_task_id = \"bda648d7-d618-4883-88f4-3466eabd860e\" # web search + pdf analysis\n",
    "country_with_list_medals_task_id = \"cf106601-ab4f-4af9-b045-5295fe67b37d\" # web search + small table processing\n",
    "country_no_longer_exists_web_search_task_id = \"5a0c1adf-205e-4841-a666-7c3ef95def9d\"\n",
    "\n",
    "evaluation_tasks = [\n",
    "    # just_running_python_task_id,\n",
    "    # sosa_many_studio_albums_task_id,\n",
    "    # calc_sales_xlsx_task_id,\n",
    "    # running_to_the_moon_task_id,\n",
    "\n",
    "    # merriam_webster_word_task_id,\n",
    "    # looking_up_paper_authors_task_id,\n",
    "\n",
    "    # baseball_table_processing_task_id,\n",
    "    # just_browser_search_task_id\n",
    "]\n",
    "\n",
    "results = []\n",
    "dataset_questions = { sample[\"task_id\"]:sample for sample in dataset }\n",
    "for sample_task_id in evaluation_tasks:\n",
    "    sample = dataset_questions[sample_task_id]\n",
    "    [ print(k, \"=\", sample[k]) for k in gaia_keys ]\n",
    "\n",
    "    mlflow.langchain.autolog()                                               # this is needed to register traces within the experiment\n",
    "    experiment_name = f\"gaia_{\"_\".join(sample[\"task_id\"].split(\"-\"))}\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.models.set_model(generalist_graph)\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    experiment_url = mlflow.get_experiment_by_name(experiment_name)\n",
    "    # mlflow.set_tracking_uri('http://localhost:5000')\n",
    "\n",
    "    question = sample[\"Question\"]\n",
    "    resources = []\n",
    "    if sample[\"file_path\"]:\n",
    "        resource = ContentResource(\n",
    "            provided_by=\"user\",\n",
    "            content=\"file provided with the main task\",\n",
    "            link=os.path.join(os.environ.get(\"HUGGING_FACE_GAIA_FOLDER_PATH\"), sample[\"file_path\"]),\n",
    "            metadata={\"note\":\"the file is already in the list of available resources\"}\n",
    "        )\n",
    "        print(resource.link)\n",
    "        resources.append(resource)\n",
    "    initial_state = init_state(question, resources=resources)\n",
    "    final_state = generalist_graph.invoke(initial_state)\n",
    "    answers = final_state[\"answers\"]\n",
    "    results.append((sample, {\"answers\":answers, \"experiment_url\": experiment_url}))"
   ],
   "id": "ba4ee28d950c37fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "[print(r,\"\\n\") for r in results]",
   "id": "ffcba280ad480033",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
