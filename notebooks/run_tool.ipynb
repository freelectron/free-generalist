{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run just a single tool, not the whole agent",
   "id": "d1cecffbb539e5fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run Code Writer & Executer\n",
    "from generalist.tools.summarisers import construct_short_answer\n",
    "from generalist.tools.code import write_python_eda, run_code, write_python_task\n",
    "\n",
    "# Usually would be a specific class, but either way ends up being a string\n",
    "activity = \"Calculate the total time in hours it would take Eliud Kipchoge to run a distance of approximately 356,870 km using his marathon pace of roughly 2.0167 hours per 42.2 kilometers\"\n",
    "resources = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"provided_by\": \"user\",\n",
    "    \"content\": \"Wikipedia page for the Moon with minimum perigee value\",\n",
    "    \"link\": \"https://en.wikipedia.org/wiki/Moon\",\n",
    "    \"metadata\": {}\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "eda_code = write_python_eda(resources)\n",
    "eda_result = run_code(eda_code)\n",
    "task_code = write_python_task(task=activity, eda_results=eda_result, resources=resources)\n",
    "result = run_code(task_code)\n",
    "short_answers = [construct_short_answer(activity, result)]"
   ],
   "id": "c3b0f40a5bdf7c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from generalist.tools.data_model import ContentResource\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import mlflow\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "load_dotenv()\n",
    "\n",
    "gaia_path = os.environ.get(\"HUGGING_FACE_GAIA_FOLDER_PATH\")\n",
    "data_dir = snapshot_download(local_dir=gaia_path,  local_files_only=True, repo_id=\"gaia-benchmark/GAIA\", repo_type=\"dataset\")\n",
    "\n",
    "dataset = load_dataset(data_dir, \"2023_level1\", split=\"validation\")\n",
    "gaia_keys = ['task_id', 'Question', 'Level', 'Final answer', 'file_name', 'file_path', 'Annotator Metadata']\n",
    "\n",
    "sosa_many_studio_albums_task_id = \"8e867cd7-cff9-4e6c-867a-ff5ddc2550be\"\n",
    "running_to_the_moon_task_id = \"e1fc63a2-da7a-432f-be78-7c4a95598703\"\n",
    "dr_who_season_9_eps_11_location_task_id = \"4b6bb5f7-f634-410e-815d-e673ab7f8632\"\n",
    "calc_sales_xlsx_task_id = \"7bd855d8-463d-4ed5-93ca-5fe35145f733\"\n",
    "just_running_python_task_id = \"f918266a-b3e0-4914-865d-4faa564f1aef\"\n",
    "evaluation_tasks = [\n",
    "    just_running_python_task_id,\n",
    "    calc_sales_xlsx_task_id,\n",
    "    sosa_many_studio_albums_task_id,\n",
    "    running_to_the_moon_task_id,\n",
    "]\n",
    "\n",
    "results = []\n",
    "dataset_questions = { sample[\"task_id\"]:sample for sample in dataset }\n",
    "for sample_task_id in evaluation_tasks:\n",
    "    sample = dataset_questions[sample_task_id]\n",
    "    [ print(k, \"=\", sample[k]) for k in gaia_keys]\n",
    "\n",
    "    mlflow.langchain.autolog()                                                 # this is needed to register traces within the experiment\n",
    "    experiment_name = f\"gaia_{\"_\".join(sample[\"task_id\"].split(\"-\"))}\"\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    question = sample[\"Question\"]\n",
    "    resources = []\n",
    "    if sample[\"file_path\"]:\n",
    "        resource = ContentResource(\n",
    "            provided_by=\"user\",\n",
    "            content=\"file provided with the main task\",\n",
    "            link=os.path.join(os.environ.get(\"HUGGING_FACE_GAIA_FOLDER_PATH\"), sample[\"file_path\"]),\n",
    "            metadata={\"note\":\"the file is already in the list of available resources\"}\n",
    "        )\n",
    "        print(resource.link)\n",
    "        resources.append(resource)\n"
   ],
   "id": "2d30f690b14cc15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T14:36:56.956192Z",
     "start_time": "2026-01-18T14:36:39.271224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from generalist.tools.text_processing import parse_resource\n",
    "\n",
    "parse_resource(\"hello, use youtube to search for video related to distributed transformer training\")"
   ],
   "id": "80f236d15778c0cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim.rostov/pdev/freelectron/free-generalist/.venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2026-01-18 15:36:56,745 - generalist.tools.text_processing - parse_resource:78 - INFO - - parse_resource -- JSON to parse to determine resources: Out:\n",
      "{\n",
      " \"provided_by\": \"user_task\",\n",
      " \"content\": \"user requested to search for videos related to distributed transformer training on YouTube\",\n",
      " \"link\": \"https://www.youtube.com\"\n",
      "} \n",
      "\n",
      "Note: The link provided is the general URL of YouTube since no specific video or resource was given. If a direct link to the relevant content was expected, then further clarification from the user would be needed as none was provided in the task description.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJSONDecodeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgeneralist\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtext_processing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m parse_resource\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mparse_resource\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhello, use youtube to search for video related to distributed transformer training\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/pdev/freelectron/free-generalist/src/generalist/tools/text_processing.py:79\u001B[39m, in \u001B[36mparse_resource\u001B[39m\u001B[34m(task)\u001B[39m\n\u001B[32m     77\u001B[39m     json_content = response.text\n\u001B[32m     78\u001B[39m     logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m- \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_function()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m -- JSON to parse to determine resources: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjson_content\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     loaded_dict = \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     81\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ContentResource(\n\u001B[32m     82\u001B[39m         provided_by=loaded_dict[\u001B[33m\"\u001B[39m\u001B[33mprovided_by\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     83\u001B[39m         content=loaded_dict[\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     84\u001B[39m         link=loaded_dict[\u001B[33m\"\u001B[39m\u001B[33mlink\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     85\u001B[39m         metadata={},\n\u001B[32m     86\u001B[39m     )\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346\u001B[39m, in \u001B[36mloads\u001B[39m\u001B[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    341\u001B[39m     s = s.decode(detect_encoding(s), \u001B[33m'\u001B[39m\u001B[33msurrogatepass\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    344\u001B[39m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    345\u001B[39m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    348\u001B[39m     \u001B[38;5;28mcls\u001B[39m = JSONDecoder\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345\u001B[39m, in \u001B[36mJSONDecoder.decode\u001B[39m\u001B[34m(self, s, _w)\u001B[39m\n\u001B[32m    340\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w=WHITESPACE.match):\n\u001B[32m    341\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[33;03m    containing a JSON document).\u001B[39;00m\n\u001B[32m    343\u001B[39m \n\u001B[32m    344\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m345\u001B[39m     obj, end = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    346\u001B[39m     end = _w(s, end).end()\n\u001B[32m    347\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m end != \u001B[38;5;28mlen\u001B[39m(s):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:363\u001B[39m, in \u001B[36mJSONDecoder.raw_decode\u001B[39m\u001B[34m(self, s, idx)\u001B[39m\n\u001B[32m    361\u001B[39m     obj, end = \u001B[38;5;28mself\u001B[39m.scan_once(s, idx)\n\u001B[32m    362\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[33m\"\u001B[39m\u001B[33mExpecting value\u001B[39m\u001B[33m\"\u001B[39m, s, err.value) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[31mJSONDecodeError\u001B[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
